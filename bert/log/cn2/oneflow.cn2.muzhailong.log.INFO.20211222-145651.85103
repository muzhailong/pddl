Log file created at: 2021/12/22 14:56:51
Running on machine: cn2
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I1222 14:56:51.904511 85103 global.h:36] NewGlobal N7oneflow7EnvDescE
I1222 14:56:51.906352 85103 global.h:36] NewGlobal N7oneflow10ProcessCtxE
I1222 14:56:51.906378 85103 env_global_objects_scope.cpp:157] using rpc backend: gRPC
I1222 14:56:51.906390 85103 global.h:36] NewGlobal N7oneflow10CtrlServerE
I1222 14:56:51.907168 85103 ctrl_server.cpp:40] CtrlServer listening on 0.0.0.0:44559
I1222 14:56:51.907296 85103 rank_info_bootstrap_server.cpp:47] RankInfoBootstrapServer listening on 0.0.0.0:44021
I1222 14:57:20.106201 85103 rpc_client.cpp:187] LoadServer cn1 Successful at 0 times
I1222 14:57:20.107956 85103 ctrl_bootstrap.cpp:77] 
ctrl_addr {
  host: "cn1"
  port: 46502
}
ctrl_addr {
  host: "172.16.0.11"
  port: 35268
}
ctrl_addr {
  host: "172.16.0.12"
  port: 44559
}
ctrl_addr {
  host: "172.16.0.12"
  port: 37766
}
rank: 2
node_size: 2
I1222 14:57:50.112994 85103 rpc_client.cpp:187] LoadServer cn1 Successful at 0 times
I1222 14:57:50.113658 85103 rpc_client.cpp:187] LoadServer 172.16.0.11 Successful at 0 times
I1222 14:57:50.114710 85103 rpc_client.cpp:187] LoadServer 172.16.0.12 Successful at 0 times
I1222 14:57:50.115283 85103 rpc_client.cpp:187] LoadServer 172.16.0.12 Successful at 0 times
I1222 14:57:50.144248 85103 global.h:36] NewGlobal N7oneflow12ResourceDescE
I1222 14:57:50.144390 85103 global.h:36] NewGlobal N7oneflow12ResourceDescE
I1222 14:57:50.149427 85103 net_ib_device_descriptor.cpp:110] Inactivate port: device mlx5_0 port 
I1222 14:57:50.151803 85103 net_ib_device_descriptor.cpp:110] Inactivate port: device mlx5_1 port 
I1222 14:57:50.157085 85103 net_ib_device_descriptor.cpp:110] Inactivate port: device mlx5_3 port 
I1222 14:57:50.310740 85103 global.h:36] NewGlobal N7oneflow2ep21DeviceManagerRegistryE
I1222 14:57:50.310799 85103 global.h:36] NewGlobal N7oneflow10ThreadPoolE
I1222 14:57:50.312275 85103 global.h:36] NewGlobal N7oneflow16EagerNcclCommMgrE
I1222 14:57:50.312306 85103 global.h:36] NewGlobal N7oneflow18CudnnConvAlgoCacheE
I1222 14:57:50.312322 85103 global.h:36] NewGlobal N7oneflow2vm19VirtualMachineScopeE
I1222 14:57:50.312350 85103 global.h:36] NewGlobal N7oneflow14VirtualMachineE
I1222 14:57:50.312757 85103 virtual_machine.cpp:80] transport stream type: N7oneflow2vm13CpuStreamTypeE
I1222 14:57:50.312783 85103 virtual_machine.cpp:80] transport stream type: N7oneflow2vm14CudaStreamTypeE
I1222 14:57:50.312798 85103 virtual_machine.cpp:80] transport stream type: N7oneflow2vm19AsyncCudaStreamTypeE
I1222 14:57:50.312932 85103 global.h:36] NewGlobal N7oneflow27EagerJobBuildAndInferCtxMgrE
I1222 14:57:50.312999 85103 global.h:36] NewGlobal N7oneflow12EpollCommNetE
I1222 14:57:50.313150 85103 epoll_comm_network.cpp:63] CommNet:Epoll listening on 0.0.0.0:33673
I1222 14:57:50.330366 85103 epoll_comm_network.cpp:197] machine 0 sockfd 60
I1222 14:57:50.330405 85103 epoll_comm_network.cpp:197] machine 1 sockfd 58
I1222 14:57:50.330421 85103 epoll_comm_network.cpp:197] machine 2 sockfd -1
I1222 14:57:50.330435 85103 epoll_comm_network.cpp:197] machine 3 sockfd 56
I1222 14:57:50.330579 85103 global.h:36] NewGlobal N7oneflow9TransportE
I1222 14:57:50.330936 85103 global.h:43] DeleteGlobal N7oneflow17ForeignLockHelperE
I1222 14:57:50.331248 85103 global.h:36] NewGlobal N7oneflow25MultiClientSessionContextE
I1222 14:58:13.897145 85323 eager_nccl_comm_manager.cpp:69]  EagerNcclCommMgr::ncclCommInitRank device_vec.size() = 2, nccl_unique_id = 0200ffffffc7fffffff6ffffffac100a0b000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000, rank = 1, key = {eager_nccl_unique_id_rpc_key,0:0,2:0}
I1222 14:58:14.149672 85103 version.cpp:22] OneFlow git version: v0.5.0-381-g3677dbf43-snapshot
I1222 14:58:14.149713 85103 cuda_device_manager_factory.cpp:63] CUDA runtime version: 11.1
I1222 14:58:14.149729 85103 cuda_device_manager_factory.cpp:72] cuDNN version: 8.0.5
I1222 14:58:14.149873 85103 cuda_device_manager_factory.cpp:85] NCCL version: 2.11.4
I1222 14:58:14.150612 85103 global.h:43] DeleteGlobal N7oneflow12ResourceDescE
I1222 14:58:14.150640 85103 global.h:36] NewGlobal N7oneflow12ResourceDescE
I1222 14:58:14.150660 85103 global.h:36] NewGlobal N7oneflow5IDMgrE
I1222 14:58:14.150687 85103 global.h:36] NewGlobal N7oneflow22TaskStreamIndexManagerE
I1222 14:58:14.150701 85103 global.h:36] NewGlobal N7oneflow26LazyJobBuildAndInferCtxMgrE
I1222 14:58:14.150717 85103 global.h:36] NewGlobal N7oneflow9BufferMgrISt10shared_ptrINS_11JobInstanceEEEE
I1222 14:58:14.150732 85103 global.h:36] NewGlobal N7oneflow9BufferMgrISt10shared_ptrINS_23CriticalSectionInstanceEEEE
I1222 14:58:14.150745 85103 global.h:36] NewGlobal N7oneflow10RuntimeCtxE
I1222 14:58:14.150763 85103 global.h:36] NewGlobal N7oneflow15MemoryAllocatorE
I1222 14:58:14.150776 85103 global.h:36] NewGlobal N7oneflow8ChunkMgrE
I1222 14:58:14.150787 85103 global.h:36] NewGlobal N7oneflow8RegstMgrE
I1222 14:58:14.150802 85103 global.h:36] NewGlobal N7oneflow11ActorMsgBusE
I1222 14:58:14.150828 85103 global.h:36] NewGlobal N7oneflow9ThreadMgrE
I1222 14:58:14.150843 85103 global.h:36] NewGlobal N7oneflow15RuntimeJobDescsE
I1222 14:58:14.150856 85103 global.h:36] NewGlobal N7oneflow7summary12EventsWriterE
I1222 14:58:14.150884 85103 global.h:36] NewGlobal N7oneflow6boxing10collective9SchedulerE
I1222 14:58:14.171545 85103 global.h:36] NewGlobal N7oneflow7JobDescE
I1222 14:58:16.836542 85103 global.h:43] DeleteGlobal N7oneflow7JobDescE
I1222 14:58:16.836671 85103 global.h:36] NewGlobal N7oneflow7JobDescE
I1222 14:58:17.534137 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "reshape_872"
device_tag: "gpu"
scope_symbol_id: 4611686018436640769
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "_train_data_loader-hierarchical_parallel_cast_9/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "reshape_872/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "reshape_872"
device_tag: "gpu"
scope_symbol_id: 4611686018436640769
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "_train_data_loader-hierarchical_parallel_cast_9/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "reshape_872/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.534381 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1-reshape_444"
device_tag: "gpu"
scope_symbol_id: 4611686018433277953
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1-cast_443/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1-reshape_444/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 1
        dim: 128
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1-reshape_444"
device_tag: "gpu"
scope_symbol_id: 4611686018433277953
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1-cast_443/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1-reshape_444/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 1
        dim: 128
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.534479 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0-reshape_27"
device_tag: "gpu"
scope_symbol_id: 4611686018430058497
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0-cast_26/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0-reshape_27/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 1
        dim: 128
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0-reshape_27"
device_tag: "gpu"
scope_symbol_id: 4611686018430058497
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0-cast_26/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0-reshape_27/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 1
        dim: 128
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.534637 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1-reshape_446"
device_tag: "gpu"
scope_symbol_id: 4611686018433277953
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1-expand_445/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1-reshape_446/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 1
        dim: 128
        dim: 128
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1-reshape_446"
device_tag: "gpu"
scope_symbol_id: 4611686018433277953
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1-expand_445/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1-reshape_446/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 1
        dim: 128
        dim: 128
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.535136 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0-reshape_29"
device_tag: "gpu"
scope_symbol_id: 4611686018430058497
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0-expand_28/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0-reshape_29/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 1
        dim: 128
        dim: 128
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0-reshape_29"
device_tag: "gpu"
scope_symbol_id: 4611686018430058497
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0-expand_28/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0-reshape_29/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 1
        dim: 128
        dim: 128
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.535241 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_42"
device_tag: "gpu"
scope_symbol_id: 4611686018430103553
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self.value-broadcast_add_41/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_42/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_42"
device_tag: "gpu"
scope_symbol_id: 4611686018430103553
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self.value-broadcast_add_41/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_42/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.535362 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_38"
device_tag: "gpu"
scope_symbol_id: 4611686018430103553
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self.key-broadcast_add_37/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_38/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_38"
device_tag: "gpu"
scope_symbol_id: 4611686018430103553
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self.key-broadcast_add_37/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_38/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.535766 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_34"
device_tag: "gpu"
scope_symbol_id: 4611686018430103553
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self.query-broadcast_add_33/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_34/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_34"
device_tag: "gpu"
scope_symbol_id: 4611686018430103553
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self.query-broadcast_add_33/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_34/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.535862 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_52"
device_tag: "gpu"
scope_symbol_id: 4611686018430103553
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self-transpose_51/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_52/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_52"
device_tag: "gpu"
scope_symbol_id: 4611686018430103553
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self-transpose_51/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.0.attention.self-reshape_52/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.535981 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_76"
device_tag: "gpu"
scope_symbol_id: 4611686018430369793
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self.value-broadcast_add_75/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_76/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_76"
device_tag: "gpu"
scope_symbol_id: 4611686018430369793
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self.value-broadcast_add_75/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_76/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.536392 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_72"
device_tag: "gpu"
scope_symbol_id: 4611686018430369793
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self.key-broadcast_add_71/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_72/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_72"
device_tag: "gpu"
scope_symbol_id: 4611686018430369793
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self.key-broadcast_add_71/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_72/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.536480 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_68"
device_tag: "gpu"
scope_symbol_id: 4611686018430369793
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self.query-broadcast_add_67/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_68/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_68"
device_tag: "gpu"
scope_symbol_id: 4611686018430369793
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self.query-broadcast_add_67/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_68/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.536608 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_86"
device_tag: "gpu"
scope_symbol_id: 4611686018430369793
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self-transpose_85/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_86/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_86"
device_tag: "gpu"
scope_symbol_id: 4611686018430369793
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self-transpose_85/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.1.attention.self-reshape_86/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.537056 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_110"
device_tag: "gpu"
scope_symbol_id: 4611686018430636033
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self.value-broadcast_add_109/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_110/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_110"
device_tag: "gpu"
scope_symbol_id: 4611686018430636033
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self.value-broadcast_add_109/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_110/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.537145 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_106"
device_tag: "gpu"
scope_symbol_id: 4611686018430636033
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self.key-broadcast_add_105/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_106/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_106"
device_tag: "gpu"
scope_symbol_id: 4611686018430636033
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self.key-broadcast_add_105/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_106/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.537253 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_102"
device_tag: "gpu"
scope_symbol_id: 4611686018430636033
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self.query-broadcast_add_101/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_102/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_102"
device_tag: "gpu"
scope_symbol_id: 4611686018430636033
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self.query-broadcast_add_101/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_102/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.537658 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_120"
device_tag: "gpu"
scope_symbol_id: 4611686018430636033
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self-transpose_119/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_120/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_120"
device_tag: "gpu"
scope_symbol_id: 4611686018430636033
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self-transpose_119/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.2.attention.self-reshape_120/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.537760 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_144"
device_tag: "gpu"
scope_symbol_id: 4611686018430902273
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self.value-broadcast_add_143/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_144/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_144"
device_tag: "gpu"
scope_symbol_id: 4611686018430902273
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self.value-broadcast_add_143/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_144/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.537865 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_140"
device_tag: "gpu"
scope_symbol_id: 4611686018430902273
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self.key-broadcast_add_139/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_140/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_140"
device_tag: "gpu"
scope_symbol_id: 4611686018430902273
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self.key-broadcast_add_139/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_140/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.538249 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_136"
device_tag: "gpu"
scope_symbol_id: 4611686018430902273
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self.query-broadcast_add_135/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_136/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_136"
device_tag: "gpu"
scope_symbol_id: 4611686018430902273
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self.query-broadcast_add_135/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_136/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.538338 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_154"
device_tag: "gpu"
scope_symbol_id: 4611686018430902273
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self-transpose_153/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_154/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_154"
device_tag: "gpu"
scope_symbol_id: 4611686018430902273
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self-transpose_153/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.3.attention.self-reshape_154/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.538460 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_178"
device_tag: "gpu"
scope_symbol_id: 4611686018431168513
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self.value-broadcast_add_177/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_178/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_178"
device_tag: "gpu"
scope_symbol_id: 4611686018431168513
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self.value-broadcast_add_177/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_178/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.538851 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_174"
device_tag: "gpu"
scope_symbol_id: 4611686018431168513
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self.key-broadcast_add_173/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_174/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_174"
device_tag: "gpu"
scope_symbol_id: 4611686018431168513
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self.key-broadcast_add_173/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_174/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.538939 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_170"
device_tag: "gpu"
scope_symbol_id: 4611686018431168513
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self.query-broadcast_add_169/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_170/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_170"
device_tag: "gpu"
scope_symbol_id: 4611686018431168513
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self.query-broadcast_add_169/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_170/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.539050 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_188"
device_tag: "gpu"
scope_symbol_id: 4611686018431168513
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self-transpose_187/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_188/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_188"
device_tag: "gpu"
scope_symbol_id: 4611686018431168513
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self-transpose_187/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.4.attention.self-reshape_188/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.539520 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_212"
device_tag: "gpu"
scope_symbol_id: 4611686018431434753
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self.value-broadcast_add_211/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_212/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_212"
device_tag: "gpu"
scope_symbol_id: 4611686018431434753
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self.value-broadcast_add_211/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_212/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.539609 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_208"
device_tag: "gpu"
scope_symbol_id: 4611686018431434753
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self.key-broadcast_add_207/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_208/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_208"
device_tag: "gpu"
scope_symbol_id: 4611686018431434753
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self.key-broadcast_add_207/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_208/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.539717 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_204"
device_tag: "gpu"
scope_symbol_id: 4611686018431434753
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self.query-broadcast_add_203/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_204/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_204"
device_tag: "gpu"
scope_symbol_id: 4611686018431434753
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self.query-broadcast_add_203/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_204/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.540169 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_222"
device_tag: "gpu"
scope_symbol_id: 4611686018431434753
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self-transpose_221/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_222/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_222"
device_tag: "gpu"
scope_symbol_id: 4611686018431434753
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self-transpose_221/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.5.attention.self-reshape_222/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.540268 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_246"
device_tag: "gpu"
scope_symbol_id: 4611686018431700993
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self.value-broadcast_add_245/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_246/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_246"
device_tag: "gpu"
scope_symbol_id: 4611686018431700993
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self.value-broadcast_add_245/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_246/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.540375 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_242"
device_tag: "gpu"
scope_symbol_id: 4611686018431700993
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self.key-broadcast_add_241/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_242/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_242"
device_tag: "gpu"
scope_symbol_id: 4611686018431700993
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self.key-broadcast_add_241/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_242/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.540789 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_238"
device_tag: "gpu"
scope_symbol_id: 4611686018431700993
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self.query-broadcast_add_237/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_238/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_238"
device_tag: "gpu"
scope_symbol_id: 4611686018431700993
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self.query-broadcast_add_237/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_238/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.540881 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_256"
device_tag: "gpu"
scope_symbol_id: 4611686018431700993
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self-transpose_255/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_256/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_256"
device_tag: "gpu"
scope_symbol_id: 4611686018431700993
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self-transpose_255/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.6.attention.self-reshape_256/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.540977 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_280"
device_tag: "gpu"
scope_symbol_id: 4611686018431967233
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self.value-broadcast_add_279/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_280/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_280"
device_tag: "gpu"
scope_symbol_id: 4611686018431967233
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self.value-broadcast_add_279/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_280/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.541082 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_276"
device_tag: "gpu"
scope_symbol_id: 4611686018431967233
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self.key-broadcast_add_275/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_276/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_276"
device_tag: "gpu"
scope_symbol_id: 4611686018431967233
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self.key-broadcast_add_275/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_276/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.541478 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_272"
device_tag: "gpu"
scope_symbol_id: 4611686018431967233
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self.query-broadcast_add_271/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_272/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_272"
device_tag: "gpu"
scope_symbol_id: 4611686018431967233
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self.query-broadcast_add_271/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_272/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.541576 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_290"
device_tag: "gpu"
scope_symbol_id: 4611686018431967233
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self-transpose_289/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_290/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_290"
device_tag: "gpu"
scope_symbol_id: 4611686018431967233
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self-transpose_289/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.7.attention.self-reshape_290/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.541694 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_314"
device_tag: "gpu"
scope_symbol_id: 4611686018432233473
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self.value-broadcast_add_313/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_314/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_314"
device_tag: "gpu"
scope_symbol_id: 4611686018432233473
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self.value-broadcast_add_313/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_314/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.542143 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_310"
device_tag: "gpu"
scope_symbol_id: 4611686018432233473
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self.key-broadcast_add_309/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_310/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_310"
device_tag: "gpu"
scope_symbol_id: 4611686018432233473
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self.key-broadcast_add_309/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_310/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.542230 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_306"
device_tag: "gpu"
scope_symbol_id: 4611686018432233473
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self.query-broadcast_add_305/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_306/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_306"
device_tag: "gpu"
scope_symbol_id: 4611686018432233473
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self.query-broadcast_add_305/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_306/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.542344 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_324"
device_tag: "gpu"
scope_symbol_id: 4611686018432233473
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self-transpose_323/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_324/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_324"
device_tag: "gpu"
scope_symbol_id: 4611686018432233473
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self-transpose_323/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.8.attention.self-reshape_324/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.542732 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_348"
device_tag: "gpu"
scope_symbol_id: 4611686018432499713
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self.value-broadcast_add_347/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_348/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_348"
device_tag: "gpu"
scope_symbol_id: 4611686018432499713
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self.value-broadcast_add_347/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_348/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.542824 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_344"
device_tag: "gpu"
scope_symbol_id: 4611686018432499713
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self.key-broadcast_add_343/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_344/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_344"
device_tag: "gpu"
scope_symbol_id: 4611686018432499713
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self.key-broadcast_add_343/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_344/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.542930 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_340"
device_tag: "gpu"
scope_symbol_id: 4611686018432499713
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self.query-broadcast_add_339/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_340/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_340"
device_tag: "gpu"
scope_symbol_id: 4611686018432499713
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self.query-broadcast_add_339/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_340/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.543339 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_358"
device_tag: "gpu"
scope_symbol_id: 4611686018432499713
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self-transpose_357/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_358/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_358"
device_tag: "gpu"
scope_symbol_id: 4611686018432499713
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self-transpose_357/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.9.attention.self-reshape_358/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.543437 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_382"
device_tag: "gpu"
scope_symbol_id: 4611686018432765953
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self.value-broadcast_add_381/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_382/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_382"
device_tag: "gpu"
scope_symbol_id: 4611686018432765953
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self.value-broadcast_add_381/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_382/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.543555 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_378"
device_tag: "gpu"
scope_symbol_id: 4611686018432765953
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self.key-broadcast_add_377/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_378/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_378"
device_tag: "gpu"
scope_symbol_id: 4611686018432765953
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self.key-broadcast_add_377/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_378/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.543951 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_374"
device_tag: "gpu"
scope_symbol_id: 4611686018432765953
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self.query-broadcast_add_373/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_374/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_374"
device_tag: "gpu"
scope_symbol_id: 4611686018432765953
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self.query-broadcast_add_373/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_374/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.544046 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_392"
device_tag: "gpu"
scope_symbol_id: 4611686018432765953
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self-transpose_391/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_392/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_392"
device_tag: "gpu"
scope_symbol_id: 4611686018432765953
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self-transpose_391/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.10.attention.self-reshape_392/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.544165 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_416"
device_tag: "gpu"
scope_symbol_id: 4611686018433032193
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self.value-broadcast_add_415/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_416/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_416"
device_tag: "gpu"
scope_symbol_id: 4611686018433032193
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self.value-broadcast_add_415/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_416/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.544565 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_412"
device_tag: "gpu"
scope_symbol_id: 4611686018433032193
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self.key-broadcast_add_411/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_412/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_412"
device_tag: "gpu"
scope_symbol_id: 4611686018433032193
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self.key-broadcast_add_411/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_412/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.544653 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_408"
device_tag: "gpu"
scope_symbol_id: 4611686018433032193
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self.query-broadcast_add_407/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_408/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_408"
device_tag: "gpu"
scope_symbol_id: 4611686018433032193
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self.query-broadcast_add_407/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_408/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.544768 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_426"
device_tag: "gpu"
scope_symbol_id: 4611686018433032193
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self-transpose_425/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_426/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_426"
device_tag: "gpu"
scope_symbol_id: 4611686018433032193
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self-transpose_425/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage0.encoder.layer.11.attention.self-reshape_426/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.545178 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_459"
device_tag: "gpu"
scope_symbol_id: 4611686018433323009
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self.value-broadcast_add_458/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_459/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_459"
device_tag: "gpu"
scope_symbol_id: 4611686018433323009
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self.value-broadcast_add_458/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_459/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.545269 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_455"
device_tag: "gpu"
scope_symbol_id: 4611686018433323009
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self.key-broadcast_add_454/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_455/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_455"
device_tag: "gpu"
scope_symbol_id: 4611686018433323009
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self.key-broadcast_add_454/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_455/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.545377 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_451"
device_tag: "gpu"
scope_symbol_id: 4611686018433323009
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self.query-broadcast_add_450/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_451/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_451"
device_tag: "gpu"
scope_symbol_id: 4611686018433323009
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self.query-broadcast_add_450/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_451/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.545807 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_469"
device_tag: "gpu"
scope_symbol_id: 4611686018433323009
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self-transpose_468/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_469/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_469"
device_tag: "gpu"
scope_symbol_id: 4611686018433323009
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self-transpose_468/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.0.attention.self-reshape_469/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.545909 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_493"
device_tag: "gpu"
scope_symbol_id: 4611686018433589249
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self.value-broadcast_add_492/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_493/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_493"
device_tag: "gpu"
scope_symbol_id: 4611686018433589249
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self.value-broadcast_add_492/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_493/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.546015 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_489"
device_tag: "gpu"
scope_symbol_id: 4611686018433589249
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self.key-broadcast_add_488/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_489/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_489"
device_tag: "gpu"
scope_symbol_id: 4611686018433589249
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self.key-broadcast_add_488/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_489/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.546398 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_485"
device_tag: "gpu"
scope_symbol_id: 4611686018433589249
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self.query-broadcast_add_484/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_485/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_485"
device_tag: "gpu"
scope_symbol_id: 4611686018433589249
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self.query-broadcast_add_484/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_485/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.546491 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_503"
device_tag: "gpu"
scope_symbol_id: 4611686018433589249
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self-transpose_502/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_503/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_503"
device_tag: "gpu"
scope_symbol_id: 4611686018433589249
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self-transpose_502/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.1.attention.self-reshape_503/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.546620 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_527"
device_tag: "gpu"
scope_symbol_id: 4611686018433855489
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self.value-broadcast_add_526/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_527/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_527"
device_tag: "gpu"
scope_symbol_id: 4611686018433855489
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self.value-broadcast_add_526/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_527/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.547032 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_523"
device_tag: "gpu"
scope_symbol_id: 4611686018433855489
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self.key-broadcast_add_522/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_523/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_523"
device_tag: "gpu"
scope_symbol_id: 4611686018433855489
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self.key-broadcast_add_522/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_523/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.547122 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_519"
device_tag: "gpu"
scope_symbol_id: 4611686018433855489
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self.query-broadcast_add_518/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_519/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_519"
device_tag: "gpu"
scope_symbol_id: 4611686018433855489
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self.query-broadcast_add_518/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_519/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.547235 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_537"
device_tag: "gpu"
scope_symbol_id: 4611686018433855489
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self-transpose_536/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_537/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_537"
device_tag: "gpu"
scope_symbol_id: 4611686018433855489
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self-transpose_536/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.2.attention.self-reshape_537/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.547634 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_561"
device_tag: "gpu"
scope_symbol_id: 4611686018434121729
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self.value-broadcast_add_560/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_561/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_561"
device_tag: "gpu"
scope_symbol_id: 4611686018434121729
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self.value-broadcast_add_560/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_561/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.547721 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_557"
device_tag: "gpu"
scope_symbol_id: 4611686018434121729
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self.key-broadcast_add_556/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_557/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_557"
device_tag: "gpu"
scope_symbol_id: 4611686018434121729
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self.key-broadcast_add_556/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_557/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.547832 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_553"
device_tag: "gpu"
scope_symbol_id: 4611686018434121729
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self.query-broadcast_add_552/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_553/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_553"
device_tag: "gpu"
scope_symbol_id: 4611686018434121729
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self.query-broadcast_add_552/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_553/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.548313 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_571"
device_tag: "gpu"
scope_symbol_id: 4611686018434121729
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self-transpose_570/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_571/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_571"
device_tag: "gpu"
scope_symbol_id: 4611686018434121729
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self-transpose_570/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.3.attention.self-reshape_571/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.548449 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_595"
device_tag: "gpu"
scope_symbol_id: 4611686018434387969
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self.value-broadcast_add_594/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_595/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_595"
device_tag: "gpu"
scope_symbol_id: 4611686018434387969
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self.value-broadcast_add_594/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_595/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.548571 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_591"
device_tag: "gpu"
scope_symbol_id: 4611686018434387969
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self.key-broadcast_add_590/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_591/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_591"
device_tag: "gpu"
scope_symbol_id: 4611686018434387969
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self.key-broadcast_add_590/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_591/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.548964 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_587"
device_tag: "gpu"
scope_symbol_id: 4611686018434387969
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self.query-broadcast_add_586/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_587/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_587"
device_tag: "gpu"
scope_symbol_id: 4611686018434387969
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self.query-broadcast_add_586/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_587/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.549057 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_605"
device_tag: "gpu"
scope_symbol_id: 4611686018434387969
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self-transpose_604/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_605/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_605"
device_tag: "gpu"
scope_symbol_id: 4611686018434387969
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self-transpose_604/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.4.attention.self-reshape_605/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.549178 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_629"
device_tag: "gpu"
scope_symbol_id: 4611686018434654209
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self.value-broadcast_add_628/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_629/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_629"
device_tag: "gpu"
scope_symbol_id: 4611686018434654209
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self.value-broadcast_add_628/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_629/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.549561 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_625"
device_tag: "gpu"
scope_symbol_id: 4611686018434654209
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self.key-broadcast_add_624/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_625/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_625"
device_tag: "gpu"
scope_symbol_id: 4611686018434654209
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self.key-broadcast_add_624/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_625/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.549649 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_621"
device_tag: "gpu"
scope_symbol_id: 4611686018434654209
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self.query-broadcast_add_620/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_621/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_621"
device_tag: "gpu"
scope_symbol_id: 4611686018434654209
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self.query-broadcast_add_620/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_621/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.549759 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_639"
device_tag: "gpu"
scope_symbol_id: 4611686018434654209
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self-transpose_638/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_639/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_639"
device_tag: "gpu"
scope_symbol_id: 4611686018434654209
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self-transpose_638/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.5.attention.self-reshape_639/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.550199 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_663"
device_tag: "gpu"
scope_symbol_id: 4611686018434920449
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self.value-broadcast_add_662/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_663/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_663"
device_tag: "gpu"
scope_symbol_id: 4611686018434920449
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self.value-broadcast_add_662/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_663/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.550285 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_659"
device_tag: "gpu"
scope_symbol_id: 4611686018434920449
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self.key-broadcast_add_658/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_659/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_659"
device_tag: "gpu"
scope_symbol_id: 4611686018434920449
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self.key-broadcast_add_658/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_659/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.550393 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_655"
device_tag: "gpu"
scope_symbol_id: 4611686018434920449
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self.query-broadcast_add_654/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_655/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_655"
device_tag: "gpu"
scope_symbol_id: 4611686018434920449
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self.query-broadcast_add_654/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_655/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.550772 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_673"
device_tag: "gpu"
scope_symbol_id: 4611686018434920449
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self-transpose_672/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_673/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_673"
device_tag: "gpu"
scope_symbol_id: 4611686018434920449
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self-transpose_672/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.6.attention.self-reshape_673/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.550873 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_697"
device_tag: "gpu"
scope_symbol_id: 4611686018435186689
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self.value-broadcast_add_696/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_697/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_697"
device_tag: "gpu"
scope_symbol_id: 4611686018435186689
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self.value-broadcast_add_696/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_697/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.550981 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_693"
device_tag: "gpu"
scope_symbol_id: 4611686018435186689
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self.key-broadcast_add_692/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_693/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_693"
device_tag: "gpu"
scope_symbol_id: 4611686018435186689
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self.key-broadcast_add_692/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_693/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.551334 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_689"
device_tag: "gpu"
scope_symbol_id: 4611686018435186689
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self.query-broadcast_add_688/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_689/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_689"
device_tag: "gpu"
scope_symbol_id: 4611686018435186689
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self.query-broadcast_add_688/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_689/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.551425 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_707"
device_tag: "gpu"
scope_symbol_id: 4611686018435186689
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self-transpose_706/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_707/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_707"
device_tag: "gpu"
scope_symbol_id: 4611686018435186689
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self-transpose_706/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.7.attention.self-reshape_707/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.551550 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_731"
device_tag: "gpu"
scope_symbol_id: 4611686018435452929
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self.value-broadcast_add_730/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_731/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_731"
device_tag: "gpu"
scope_symbol_id: 4611686018435452929
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self.value-broadcast_add_730/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_731/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.551918 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_727"
device_tag: "gpu"
scope_symbol_id: 4611686018435452929
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self.key-broadcast_add_726/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_727/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_727"
device_tag: "gpu"
scope_symbol_id: 4611686018435452929
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self.key-broadcast_add_726/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_727/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.552008 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_723"
device_tag: "gpu"
scope_symbol_id: 4611686018435452929
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self.query-broadcast_add_722/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_723/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_723"
device_tag: "gpu"
scope_symbol_id: 4611686018435452929
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self.query-broadcast_add_722/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_723/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.552119 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_741"
device_tag: "gpu"
scope_symbol_id: 4611686018435452929
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self-transpose_740/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_741/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_741"
device_tag: "gpu"
scope_symbol_id: 4611686018435452929
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self-transpose_740/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.8.attention.self-reshape_741/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.552495 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_765"
device_tag: "gpu"
scope_symbol_id: 4611686018435719169
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self.value-broadcast_add_764/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_765/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_765"
device_tag: "gpu"
scope_symbol_id: 4611686018435719169
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self.value-broadcast_add_764/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_765/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.552590 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_761"
device_tag: "gpu"
scope_symbol_id: 4611686018435719169
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self.key-broadcast_add_760/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_761/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_761"
device_tag: "gpu"
scope_symbol_id: 4611686018435719169
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self.key-broadcast_add_760/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_761/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.552700 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_757"
device_tag: "gpu"
scope_symbol_id: 4611686018435719169
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self.query-broadcast_add_756/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_757/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_757"
device_tag: "gpu"
scope_symbol_id: 4611686018435719169
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self.query-broadcast_add_756/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_757/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.553086 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_775"
device_tag: "gpu"
scope_symbol_id: 4611686018435719169
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self-transpose_774/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_775/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_775"
device_tag: "gpu"
scope_symbol_id: 4611686018435719169
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self-transpose_774/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.9.attention.self-reshape_775/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.553185 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_799"
device_tag: "gpu"
scope_symbol_id: 4611686018435985409
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self.value-broadcast_add_798/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_799/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_799"
device_tag: "gpu"
scope_symbol_id: 4611686018435985409
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self.value-broadcast_add_798/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_799/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.553295 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_795"
device_tag: "gpu"
scope_symbol_id: 4611686018435985409
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self.key-broadcast_add_794/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_795/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_795"
device_tag: "gpu"
scope_symbol_id: 4611686018435985409
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self.key-broadcast_add_794/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_795/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.553655 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_791"
device_tag: "gpu"
scope_symbol_id: 4611686018435985409
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self.query-broadcast_add_790/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_791/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_791"
device_tag: "gpu"
scope_symbol_id: 4611686018435985409
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self.query-broadcast_add_790/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_791/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.553745 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_809"
device_tag: "gpu"
scope_symbol_id: 4611686018435985409
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self-transpose_808/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_809/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_809"
device_tag: "gpu"
scope_symbol_id: 4611686018435985409
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self-transpose_808/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.10.attention.self-reshape_809/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.553859 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_833"
device_tag: "gpu"
scope_symbol_id: 4611686018436251649
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self.value-broadcast_add_832/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_833/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_833"
device_tag: "gpu"
scope_symbol_id: 4611686018436251649
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self.value-broadcast_add_832/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_833/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.554226 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_829"
device_tag: "gpu"
scope_symbol_id: 4611686018436251649
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self.key-broadcast_add_828/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_829/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_829"
device_tag: "gpu"
scope_symbol_id: 4611686018436251649
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self.key-broadcast_add_828/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_829/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.554311 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_825"
device_tag: "gpu"
scope_symbol_id: 4611686018436251649
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self.query-broadcast_add_824/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_825/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_825"
device_tag: "gpu"
scope_symbol_id: 4611686018436251649
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self.query-broadcast_add_824/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_825/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 32
        dim: 64
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.554423 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_843"
device_tag: "gpu"
scope_symbol_id: 4611686018436251649
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self-transpose_842/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_843/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_843"
device_tag: "gpu"
scope_symbol_id: 4611686018436251649
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self-transpose_842/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.encoder.layer.11.attention.self-reshape_843/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 128
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.554803 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.pooler-reshape_858"
device_tag: "gpu"
scope_symbol_id: 4611686018436485121
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.pooler-slice_857/y_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.pooler-reshape_858/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.pooler-reshape_858"
device_tag: "gpu"
scope_symbol_id: 4611686018436485121
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.pooler-slice_857/y_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.pooler-reshape_858/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.554890 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "base_model.m_stage1.pooler-reshape_859"
device_tag: "gpu"
scope_symbol_id: 4611686018436485121
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.pooler-reshape_858/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.pooler-reshape_859/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "base_model.m_stage1.pooler-reshape_859"
device_tag: "gpu"
scope_symbol_id: 4611686018436485121
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.pooler-reshape_858/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "base_model.m_stage1.pooler-reshape_859/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 2048
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.555008 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "reshape_871"
device_tag: "gpu"
scope_symbol_id: 4611686018436640769
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.cls.seq_relationship-broadcast_add_870/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "reshape_871/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 2
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "reshape_871"
device_tag: "gpu"
scope_symbol_id: 4611686018436640769
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "base_model.m_stage1.cls.seq_relationship-broadcast_add_870/z_0"
    }
  }
  output {
    key: "out"
    value {
      s: "reshape_871/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 2
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.555370 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "mlm_criterion-reshape_886"
device_tag: "gpu"
scope_symbol_id: 4611686018436657153
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "mlm_criterion-transpose_885/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "mlm_criterion-reshape_886/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 640
        dim: 30522
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "mlm_criterion-reshape_886"
device_tag: "gpu"
scope_symbol_id: 4611686018436657153
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "mlm_criterion-transpose_885/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "mlm_criterion-reshape_886/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 30522
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.555460 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "ns_criterion-reshape_874"
device_tag: "gpu"
scope_symbol_id: 4611686018436648961
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "ns_criterion-transpose_873/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "ns_criterion-reshape_874/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
        dim: 2
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "ns_criterion-reshape_874"
device_tag: "gpu"
scope_symbol_id: 4611686018436648961
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "ns_criterion-transpose_873/output_0"
    }
  }
  output {
    key: "out"
    value {
      s: "ns_criterion-reshape_874/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
        dim: 2
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.555549 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "mlm_criterion-reshape_889"
device_tag: "gpu"
scope_symbol_id: 4611686018436657153
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "mlm_criterion-nll_888/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "mlm_criterion-reshape_889/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 640
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "mlm_criterion-reshape_889"
device_tag: "gpu"
scope_symbol_id: 4611686018436657153
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "mlm_criterion-nll_888/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "mlm_criterion-reshape_889/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:17.555660 85103 gradient_accumulation_rewrite_pass.cpp:186]  Replace ReshapeOpConf from: name: "ns_criterion-reshape_877"
device_tag: "gpu"
scope_symbol_id: 4611686018436648961
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "ns_criterion-nll_876/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "ns_criterion-reshape_877/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: 32
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 to name: "ns_criterion-reshape_877"
device_tag: "gpu"
scope_symbol_id: 4611686018436648961
user_conf {
  op_type_name: "reshape"
  input {
    key: "in"
    value {
      s: "ns_criterion-nll_876/out_0"
    }
  }
  output {
    key: "out"
    value {
      s: "ns_criterion-reshape_877/out_0"
    }
  }
  attr {
    key: "shape"
    value {
      at_shape {
        dim: -1
      }
    }
  }
  input_order: "in"
  output_order: "out"
}
 for dynamic infer by insert unpack.
I1222 14:58:24.395970 85103 fix_pipeline_stage_id_pass.cpp:104] total stage num = 2
I1222 14:58:24.408092 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: base_model-identity_441 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.408280 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: base_model-identity_442 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.408519 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: reshape_871 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.408596 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: reshape_872 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.408630 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-transpose_873 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.408690 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-reshape_874 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.408723 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-log_softmax_875 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.408752 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-nll_876 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.408783 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-reshape_877 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.408814 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-reduce_sum_878 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.408844 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-broadcast_div_879 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.408872 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: expand_dims_880 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.408955 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: expand_881 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.409727 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: dim_gather_882 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.409759 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: reshape_883 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.409787 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: reshape_884 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.409813 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: mlm_criterion-transpose_885 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.409878 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: mlm_criterion-reshape_886 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.409912 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: mlm_criterion-log_softmax_887 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.409941 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: mlm_criterion-nll_888 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.409971 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: mlm_criterion-reshape_889 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410001 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: reshape_890 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410028 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: multiply_891 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410055 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: reduce_sum_892 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410082 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: reduce_sum_893 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410109 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: scalar_add_894 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410137 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: broadcast_div_895 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410162 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: add_n_896 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410218 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: _PipelineGraph_0-output_0 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410768 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: _PipelineGraph_0-output_1 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410795 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: _PipelineGraph_0-output_2 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410882 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: System-GradientAccumulation-ReturnPack-_PipelineGraph_0-output_2 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410913 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: System-GradientAccumulation-ReturnPack-_PipelineGraph_0-output_1 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410943 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: System-GradientAccumulation-ReturnPack-_PipelineGraph_0-output_0 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.410969 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: add_n_896_out_0_grad_ConstantLike origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.411026 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-broadcast_div_879_grad_x_div origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.411082 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-broadcast_div_879_y_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.411115 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: broadcast_div_895_grad_x_div origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.411144 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-reduce_sum_878_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.411173 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: reduce_sum_892_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.411201 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-reshape_877_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.411231 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: multiply_891_x_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.411257 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-nll_876_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.411317 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: reshape_890_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.411948 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-log_softmax_875_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.411979 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: mlm_criterion-reshape_889_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412035 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-reshape_874_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412070 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: mlm_criterion-nll_888_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412101 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: ns_criterion-transpose_873_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412130 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: mlm_criterion-log_softmax_887_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412159 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: reshape_871_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412187 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: mlm_criterion-reshape_886_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412216 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: mlm_criterion-transpose_885_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412245 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: reshape_883_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412273 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: dim_gather_882_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412488 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: base_model-identity_441_clone_grad_473 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412560 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: base_model-identity_441_grad origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412659 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: System-ClipGradient-GlobalNorm-MultiSquareSum-1696 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:24.412811 85103 fix_pipeline_stage_id_pass.cpp:128]  In FixPipelineStageIdPass, op_name: System-ClipGradient-GlobalNorm-MultiSquareSum-1853 origin_stage_id = 0 is different with same placement : gpu,{1:[1,],3:[1,],} max_stage_id: 1 , so change this op to the max stage id.
I1222 14:58:25.161291 85103 pipeline_buffer_pass.cpp:245] total stage num = 2
I1222 14:58:25.163033 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.output.LayerNorm-layer_norm_439-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.output.LayerNorm-layer_norm_439] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.output.LayerNorm-layer_norm_439_param_grad] (stage_id:0) 
I1222 14:58:25.163125 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.output-add_n_438-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.output-add_n_438] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.output.LayerNorm-layer_norm_439_grad] (stage_id:0) 
I1222 14:58:25.163185 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.output.LayerNorm-layer_norm_439-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.output.LayerNorm-layer_norm_439] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.output.LayerNorm-layer_norm_439_grad] (stage_id:0) 
I1222 14:58:25.163237 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.output.LayerNorm-layer_norm_439-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.output.LayerNorm-layer_norm_439] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.output.LayerNorm-layer_norm_439_grad] (stage_id:0) 
I1222 14:58:25.163293 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.output.dropout-dropout_437-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.output.dropout-dropout_437] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.output.dropout-dropout_437_grad] (stage_id:0) 
I1222 14:58:25.163354 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.intermediate.intermediate_act_fn-gelu_434-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.intermediate.intermediate_act_fn-gelu_434] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.output.dense-broadcast_matmul_435_b_grad] (stage_id:0) 
I1222 14:58:25.163412 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.intermediate.dense-broadcast_add_433-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.intermediate.dense-broadcast_add_433] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.intermediate.intermediate_act_fn-gelu_434_grad] (stage_id:0) 
I1222 14:58:25.163471 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.output.LayerNorm-layer_norm_431-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.output.LayerNorm-layer_norm_431] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.intermediate.dense-broadcast_matmul_432_b_grad] (stage_id:0) 
I1222 14:58:25.163532 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.output.LayerNorm-layer_norm_431-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.output.LayerNorm-layer_norm_431] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.output.LayerNorm-layer_norm_431_param_grad] (stage_id:0) 
I1222 14:58:25.163591 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.output-add_n_430-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.output-add_n_430] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.output.LayerNorm-layer_norm_431_grad] (stage_id:0) 
I1222 14:58:25.163707 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.output.LayerNorm-layer_norm_431-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.output.LayerNorm-layer_norm_431] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.output.LayerNorm-layer_norm_431_grad] (stage_id:0) 
I1222 14:58:25.164350 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.output.LayerNorm-layer_norm_431-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.output.LayerNorm-layer_norm_431] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.output.LayerNorm-layer_norm_431_grad] (stage_id:0) 
I1222 14:58:25.164405 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.output.dropout-dropout_429-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.output.dropout-dropout_429] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.output.dropout-dropout_429_grad] (stage_id:0) 
I1222 14:58:25.164467 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.self-reshape_426-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.self-reshape_426] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.output.dense-broadcast_matmul_427_b_grad] (stage_id:0) 
I1222 14:58:25.164530 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.self-transpose_417-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.self-transpose_417] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.self-batch_matmul_424_grad_a] (stage_id:0) 
I1222 14:58:25.164587 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.self.dropout-dropout_423-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.self.dropout-dropout_423] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.self-batch_matmul_424_grad_b] (stage_id:0) 
I1222 14:58:25.164642 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.self.dropout-dropout_423-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.self.dropout-dropout_423] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.self.dropout-dropout_423_grad] (stage_id:0) 
I1222 14:58:25.164696 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.self-softmax_422-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.self-softmax_422] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.self-softmax_422_grad] (stage_id:0) 
I1222 14:58:25.164757 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.output.LayerNorm-layer_norm_405-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.output.LayerNorm-layer_norm_405] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.self.value-broadcast_matmul_414_b_grad] (stage_id:0) 
I1222 14:58:25.164811 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.self-transpose_418-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.self-transpose_418] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.self-batch_matmul_419_grad_a] (stage_id:0) 
I1222 14:58:25.164893 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.11.attention.self-transpose_409-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.11.attention.self-transpose_409] (stage_id:0) -> [base_model.m_stage0.encoder.layer.11.attention.self-batch_matmul_419_grad_b] (stage_id:0) 
I1222 14:58:25.165544 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.output.LayerNorm-layer_norm_405-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.output.LayerNorm-layer_norm_405] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.output.LayerNorm-layer_norm_405_param_grad] (stage_id:0) 
I1222 14:58:25.165606 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.output-add_n_404-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.output-add_n_404] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.output.LayerNorm-layer_norm_405_grad] (stage_id:0) 
I1222 14:58:25.165659 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.output.LayerNorm-layer_norm_405-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.output.LayerNorm-layer_norm_405] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.output.LayerNorm-layer_norm_405_grad] (stage_id:0) 
I1222 14:58:25.165706 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.output.LayerNorm-layer_norm_405-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.output.LayerNorm-layer_norm_405] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.output.LayerNorm-layer_norm_405_grad] (stage_id:0) 
I1222 14:58:25.165761 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.output.dropout-dropout_403-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.output.dropout-dropout_403] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.output.dropout-dropout_403_grad] (stage_id:0) 
I1222 14:58:25.165819 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.intermediate.intermediate_act_fn-gelu_400-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.intermediate.intermediate_act_fn-gelu_400] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.output.dense-broadcast_matmul_401_b_grad] (stage_id:0) 
I1222 14:58:25.165875 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.intermediate.dense-broadcast_add_399-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.intermediate.dense-broadcast_add_399] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.intermediate.intermediate_act_fn-gelu_400_grad] (stage_id:0) 
I1222 14:58:25.165935 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.output.LayerNorm-layer_norm_397-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.output.LayerNorm-layer_norm_397] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.intermediate.dense-broadcast_matmul_398_b_grad] (stage_id:0) 
I1222 14:58:25.165992 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.output.LayerNorm-layer_norm_397-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.output.LayerNorm-layer_norm_397] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.output.LayerNorm-layer_norm_397_param_grad] (stage_id:0) 
I1222 14:58:25.166079 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.output-add_n_396-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.output-add_n_396] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.output.LayerNorm-layer_norm_397_grad] (stage_id:0) 
I1222 14:58:25.166678 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.output.LayerNorm-layer_norm_397-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.output.LayerNorm-layer_norm_397] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.output.LayerNorm-layer_norm_397_grad] (stage_id:0) 
I1222 14:58:25.166728 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.output.LayerNorm-layer_norm_397-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.output.LayerNorm-layer_norm_397] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.output.LayerNorm-layer_norm_397_grad] (stage_id:0) 
I1222 14:58:25.166780 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.output.dropout-dropout_395-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.output.dropout-dropout_395] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.output.dropout-dropout_395_grad] (stage_id:0) 
I1222 14:58:25.166838 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.self-reshape_392-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.self-reshape_392] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.output.dense-broadcast_matmul_393_b_grad] (stage_id:0) 
I1222 14:58:25.166895 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.self-transpose_383-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.self-transpose_383] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.self-batch_matmul_390_grad_a] (stage_id:0) 
I1222 14:58:25.166951 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.self.dropout-dropout_389-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.self.dropout-dropout_389] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.self-batch_matmul_390_grad_b] (stage_id:0) 
I1222 14:58:25.167006 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.self.dropout-dropout_389-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.self.dropout-dropout_389] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.self.dropout-dropout_389_grad] (stage_id:0) 
I1222 14:58:25.167060 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.self-softmax_388-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.self-softmax_388] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.self-softmax_388_grad] (stage_id:0) 
I1222 14:58:25.167119 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.output.LayerNorm-layer_norm_371-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.output.LayerNorm-layer_norm_371] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.self.value-broadcast_matmul_380_b_grad] (stage_id:0) 
I1222 14:58:25.167201 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.self-transpose_384-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.self-transpose_384] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.self-batch_matmul_385_grad_a] (stage_id:0) 
I1222 14:58:25.167798 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.10.attention.self-transpose_375-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.10.attention.self-transpose_375] (stage_id:0) -> [base_model.m_stage0.encoder.layer.10.attention.self-batch_matmul_385_grad_b] (stage_id:0) 
I1222 14:58:25.167898 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.output.LayerNorm-layer_norm_371-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.output.LayerNorm-layer_norm_371] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.output.LayerNorm-layer_norm_371_param_grad] (stage_id:0) 
I1222 14:58:25.167956 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.output-add_n_370-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.output-add_n_370] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.output.LayerNorm-layer_norm_371_grad] (stage_id:0) 
I1222 14:58:25.168007 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.output.LayerNorm-layer_norm_371-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.output.LayerNorm-layer_norm_371] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.output.LayerNorm-layer_norm_371_grad] (stage_id:0) 
I1222 14:58:25.168056 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.output.LayerNorm-layer_norm_371-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.output.LayerNorm-layer_norm_371] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.output.LayerNorm-layer_norm_371_grad] (stage_id:0) 
I1222 14:58:25.168109 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.output.dropout-dropout_369-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.output.dropout-dropout_369] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.output.dropout-dropout_369_grad] (stage_id:0) 
I1222 14:58:25.168169 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.intermediate.intermediate_act_fn-gelu_366-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.intermediate.intermediate_act_fn-gelu_366] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.output.dense-broadcast_matmul_367_b_grad] (stage_id:0) 
I1222 14:58:25.168226 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.intermediate.dense-broadcast_add_365-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.intermediate.dense-broadcast_add_365] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.intermediate.intermediate_act_fn-gelu_366_grad] (stage_id:0) 
I1222 14:58:25.168282 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.output.LayerNorm-layer_norm_363-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.output.LayerNorm-layer_norm_363] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.intermediate.dense-broadcast_matmul_364_b_grad] (stage_id:0) 
I1222 14:58:25.168337 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.output.LayerNorm-layer_norm_363-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.output.LayerNorm-layer_norm_363] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.output.LayerNorm-layer_norm_363_param_grad] (stage_id:0) 
I1222 14:58:25.168424 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.output-add_n_362-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.output-add_n_362] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.output.LayerNorm-layer_norm_363_grad] (stage_id:0) 
I1222 14:58:25.169056 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.output.LayerNorm-layer_norm_363-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.output.LayerNorm-layer_norm_363] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.output.LayerNorm-layer_norm_363_grad] (stage_id:0) 
I1222 14:58:25.169106 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.output.LayerNorm-layer_norm_363-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.output.LayerNorm-layer_norm_363] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.output.LayerNorm-layer_norm_363_grad] (stage_id:0) 
I1222 14:58:25.169160 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.output.dropout-dropout_361-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.output.dropout-dropout_361] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.output.dropout-dropout_361_grad] (stage_id:0) 
I1222 14:58:25.169220 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.self-reshape_358-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.self-reshape_358] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.output.dense-broadcast_matmul_359_b_grad] (stage_id:0) 
I1222 14:58:25.169278 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.self-transpose_349-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.self-transpose_349] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.self-batch_matmul_356_grad_a] (stage_id:0) 
I1222 14:58:25.169332 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.self.dropout-dropout_355-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.self.dropout-dropout_355] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.self-batch_matmul_356_grad_b] (stage_id:0) 
I1222 14:58:25.169387 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.self.dropout-dropout_355-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.self.dropout-dropout_355] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.self.dropout-dropout_355_grad] (stage_id:0) 
I1222 14:58:25.169446 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.self-softmax_354-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.self-softmax_354] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.self-softmax_354_grad] (stage_id:0) 
I1222 14:58:25.169510 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.output.LayerNorm-layer_norm_337-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.output.LayerNorm-layer_norm_337] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.self.value-broadcast_matmul_346_b_grad] (stage_id:0) 
I1222 14:58:25.169597 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.self-transpose_350-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.self-transpose_350] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.self-batch_matmul_351_grad_a] (stage_id:0) 
I1222 14:58:25.170222 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.9.attention.self-transpose_341-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.9.attention.self-transpose_341] (stage_id:0) -> [base_model.m_stage0.encoder.layer.9.attention.self-batch_matmul_351_grad_b] (stage_id:0) 
I1222 14:58:25.170320 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.output.LayerNorm-layer_norm_337-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.output.LayerNorm-layer_norm_337] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.output.LayerNorm-layer_norm_337_param_grad] (stage_id:0) 
I1222 14:58:25.170377 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.output-add_n_336-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.output-add_n_336] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.output.LayerNorm-layer_norm_337_grad] (stage_id:0) 
I1222 14:58:25.170430 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.output.LayerNorm-layer_norm_337-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.output.LayerNorm-layer_norm_337] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.output.LayerNorm-layer_norm_337_grad] (stage_id:0) 
I1222 14:58:25.170477 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.output.LayerNorm-layer_norm_337-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.output.LayerNorm-layer_norm_337] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.output.LayerNorm-layer_norm_337_grad] (stage_id:0) 
I1222 14:58:25.170536 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.output.dropout-dropout_335-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.output.dropout-dropout_335] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.output.dropout-dropout_335_grad] (stage_id:0) 
I1222 14:58:25.170599 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.intermediate.intermediate_act_fn-gelu_332-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.intermediate.intermediate_act_fn-gelu_332] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.output.dense-broadcast_matmul_333_b_grad] (stage_id:0) 
I1222 14:58:25.170655 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.intermediate.dense-broadcast_add_331-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.intermediate.dense-broadcast_add_331] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.intermediate.intermediate_act_fn-gelu_332_grad] (stage_id:0) 
I1222 14:58:25.170712 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.output.LayerNorm-layer_norm_329-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.output.LayerNorm-layer_norm_329] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.intermediate.dense-broadcast_matmul_330_b_grad] (stage_id:0) 
I1222 14:58:25.170797 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.output.LayerNorm-layer_norm_329-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.output.LayerNorm-layer_norm_329] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.output.LayerNorm-layer_norm_329_param_grad] (stage_id:0) 
I1222 14:58:25.171387 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.output-add_n_328-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.output-add_n_328] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.output.LayerNorm-layer_norm_329_grad] (stage_id:0) 
I1222 14:58:25.171443 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.output.LayerNorm-layer_norm_329-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.output.LayerNorm-layer_norm_329] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.output.LayerNorm-layer_norm_329_grad] (stage_id:0) 
I1222 14:58:25.171491 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.output.LayerNorm-layer_norm_329-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.output.LayerNorm-layer_norm_329] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.output.LayerNorm-layer_norm_329_grad] (stage_id:0) 
I1222 14:58:25.171550 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.output.dropout-dropout_327-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.output.dropout-dropout_327] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.output.dropout-dropout_327_grad] (stage_id:0) 
I1222 14:58:25.171608 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.self-reshape_324-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.self-reshape_324] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.output.dense-broadcast_matmul_325_b_grad] (stage_id:0) 
I1222 14:58:25.171666 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.self-transpose_315-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.self-transpose_315] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.self-batch_matmul_322_grad_a] (stage_id:0) 
I1222 14:58:25.171720 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.self.dropout-dropout_321-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.self.dropout-dropout_321] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.self-batch_matmul_322_grad_b] (stage_id:0) 
I1222 14:58:25.171774 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.self.dropout-dropout_321-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.self.dropout-dropout_321] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.self.dropout-dropout_321_grad] (stage_id:0) 
I1222 14:58:25.171829 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.self-softmax_320-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.self-softmax_320] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.self-softmax_320_grad] (stage_id:0) 
I1222 14:58:25.171914 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.output.LayerNorm-layer_norm_303-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.output.LayerNorm-layer_norm_303] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.self.value-broadcast_matmul_312_b_grad] (stage_id:0) 
I1222 14:58:25.172469 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.self-transpose_316-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.self-transpose_316] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.self-batch_matmul_317_grad_a] (stage_id:0) 
I1222 14:58:25.172530 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.8.attention.self-transpose_307-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.8.attention.self-transpose_307] (stage_id:0) -> [base_model.m_stage0.encoder.layer.8.attention.self-batch_matmul_317_grad_b] (stage_id:0) 
I1222 14:58:25.172628 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.output.LayerNorm-layer_norm_303-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.output.LayerNorm-layer_norm_303] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.output.LayerNorm-layer_norm_303_param_grad] (stage_id:0) 
I1222 14:58:25.172686 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.output-add_n_302-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.output-add_n_302] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.output.LayerNorm-layer_norm_303_grad] (stage_id:0) 
I1222 14:58:25.172739 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.output.LayerNorm-layer_norm_303-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.output.LayerNorm-layer_norm_303] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.output.LayerNorm-layer_norm_303_grad] (stage_id:0) 
I1222 14:58:25.172786 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.output.LayerNorm-layer_norm_303-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.output.LayerNorm-layer_norm_303] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.output.LayerNorm-layer_norm_303_grad] (stage_id:0) 
I1222 14:58:25.172839 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.output.dropout-dropout_301-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.output.dropout-dropout_301] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.output.dropout-dropout_301_grad] (stage_id:0) 
I1222 14:58:25.172897 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.intermediate.intermediate_act_fn-gelu_298-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.intermediate.intermediate_act_fn-gelu_298] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.output.dense-broadcast_matmul_299_b_grad] (stage_id:0) 
I1222 14:58:25.172952 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.intermediate.dense-broadcast_add_297-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.intermediate.dense-broadcast_add_297] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.intermediate.intermediate_act_fn-gelu_298_grad] (stage_id:0) 
I1222 14:58:25.173009 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.output.LayerNorm-layer_norm_295-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.output.LayerNorm-layer_norm_295] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.intermediate.dense-broadcast_matmul_296_b_grad] (stage_id:0) 
I1222 14:58:25.173095 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.output.LayerNorm-layer_norm_295-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.output.LayerNorm-layer_norm_295] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.output.LayerNorm-layer_norm_295_param_grad] (stage_id:0) 
I1222 14:58:25.173746 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.output-add_n_294-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.output-add_n_294] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.output.LayerNorm-layer_norm_295_grad] (stage_id:0) 
I1222 14:58:25.173802 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.output.LayerNorm-layer_norm_295-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.output.LayerNorm-layer_norm_295] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.output.LayerNorm-layer_norm_295_grad] (stage_id:0) 
I1222 14:58:25.173849 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.output.LayerNorm-layer_norm_295-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.output.LayerNorm-layer_norm_295] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.output.LayerNorm-layer_norm_295_grad] (stage_id:0) 
I1222 14:58:25.173902 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.output.dropout-dropout_293-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.output.dropout-dropout_293] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.output.dropout-dropout_293_grad] (stage_id:0) 
I1222 14:58:25.173961 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.self-reshape_290-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.self-reshape_290] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.output.dense-broadcast_matmul_291_b_grad] (stage_id:0) 
I1222 14:58:25.174019 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.self-transpose_281-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.self-transpose_281] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.self-batch_matmul_288_grad_a] (stage_id:0) 
I1222 14:58:25.174074 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.self.dropout-dropout_287-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.self.dropout-dropout_287] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.self-batch_matmul_288_grad_b] (stage_id:0) 
I1222 14:58:25.174127 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.self.dropout-dropout_287-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.self.dropout-dropout_287] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.self.dropout-dropout_287_grad] (stage_id:0) 
I1222 14:58:25.174180 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.self-softmax_286-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.self-softmax_286] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.self-softmax_286_grad] (stage_id:0) 
I1222 14:58:25.174266 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.output.LayerNorm-layer_norm_269-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.output.LayerNorm-layer_norm_269] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.self.value-broadcast_matmul_278_b_grad] (stage_id:0) 
I1222 14:58:25.175457 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.self-transpose_282-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.self-transpose_282] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.self-batch_matmul_283_grad_a] (stage_id:0) 
I1222 14:58:25.175521 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.7.attention.self-transpose_273-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.7.attention.self-transpose_273] (stage_id:0) -> [base_model.m_stage0.encoder.layer.7.attention.self-batch_matmul_283_grad_b] (stage_id:0) 
I1222 14:58:25.175616 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.output.LayerNorm-layer_norm_269-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.output.LayerNorm-layer_norm_269] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.output.LayerNorm-layer_norm_269_param_grad] (stage_id:0) 
I1222 14:58:25.175674 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.output-add_n_268-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.output-add_n_268] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.output.LayerNorm-layer_norm_269_grad] (stage_id:0) 
I1222 14:58:25.175726 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.output.LayerNorm-layer_norm_269-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.output.LayerNorm-layer_norm_269] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.output.LayerNorm-layer_norm_269_grad] (stage_id:0) 
I1222 14:58:25.175773 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.output.LayerNorm-layer_norm_269-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.output.LayerNorm-layer_norm_269] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.output.LayerNorm-layer_norm_269_grad] (stage_id:0) 
I1222 14:58:25.175827 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.output.dropout-dropout_267-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.output.dropout-dropout_267] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.output.dropout-dropout_267_grad] (stage_id:0) 
I1222 14:58:25.175885 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.intermediate.intermediate_act_fn-gelu_264-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.intermediate.intermediate_act_fn-gelu_264] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.output.dense-broadcast_matmul_265_b_grad] (stage_id:0) 
I1222 14:58:25.175940 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.intermediate.dense-broadcast_add_263-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.intermediate.dense-broadcast_add_263] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.intermediate.intermediate_act_fn-gelu_264_grad] (stage_id:0) 
I1222 14:58:25.176026 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.output.LayerNorm-layer_norm_261-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.output.LayerNorm-layer_norm_261] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.intermediate.dense-broadcast_matmul_262_b_grad] (stage_id:0) 
I1222 14:58:25.177953 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.output.LayerNorm-layer_norm_261-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.output.LayerNorm-layer_norm_261] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.output.LayerNorm-layer_norm_261_param_grad] (stage_id:0) 
I1222 14:58:25.178011 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.output-add_n_260-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.output-add_n_260] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.output.LayerNorm-layer_norm_261_grad] (stage_id:0) 
I1222 14:58:25.178064 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.output.LayerNorm-layer_norm_261-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.output.LayerNorm-layer_norm_261] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.output.LayerNorm-layer_norm_261_grad] (stage_id:0) 
I1222 14:58:25.178112 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.output.LayerNorm-layer_norm_261-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.output.LayerNorm-layer_norm_261] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.output.LayerNorm-layer_norm_261_grad] (stage_id:0) 
I1222 14:58:25.178165 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.output.dropout-dropout_259-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.output.dropout-dropout_259] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.output.dropout-dropout_259_grad] (stage_id:0) 
I1222 14:58:25.178225 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.self-reshape_256-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.self-reshape_256] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.output.dense-broadcast_matmul_257_b_grad] (stage_id:0) 
I1222 14:58:25.178282 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.self-transpose_247-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.self-transpose_247] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.self-batch_matmul_254_grad_a] (stage_id:0) 
I1222 14:58:25.178335 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.self.dropout-dropout_253-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.self.dropout-dropout_253] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.self-batch_matmul_254_grad_b] (stage_id:0) 
I1222 14:58:25.178390 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.self.dropout-dropout_253-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.self.dropout-dropout_253] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.self.dropout-dropout_253_grad] (stage_id:0) 
I1222 14:58:25.178470 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.self-softmax_252-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.self-softmax_252] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.self-softmax_252_grad] (stage_id:0) 
I1222 14:58:25.179077 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.output.LayerNorm-layer_norm_235-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.output.LayerNorm-layer_norm_235] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.self.value-broadcast_matmul_244_b_grad] (stage_id:0) 
I1222 14:58:25.179136 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.self-transpose_248-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.self-transpose_248] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.self-batch_matmul_249_grad_a] (stage_id:0) 
I1222 14:58:25.179188 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.6.attention.self-transpose_239-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.6.attention.self-transpose_239] (stage_id:0) -> [base_model.m_stage0.encoder.layer.6.attention.self-batch_matmul_249_grad_b] (stage_id:0) 
I1222 14:58:25.179284 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.output.LayerNorm-layer_norm_235-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.output.LayerNorm-layer_norm_235] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.output.LayerNorm-layer_norm_235_param_grad] (stage_id:0) 
I1222 14:58:25.179349 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.output-add_n_234-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.output-add_n_234] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.output.LayerNorm-layer_norm_235_grad] (stage_id:0) 
I1222 14:58:25.179404 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.output.LayerNorm-layer_norm_235-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.output.LayerNorm-layer_norm_235] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.output.LayerNorm-layer_norm_235_grad] (stage_id:0) 
I1222 14:58:25.179451 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.output.LayerNorm-layer_norm_235-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.output.LayerNorm-layer_norm_235] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.output.LayerNorm-layer_norm_235_grad] (stage_id:0) 
I1222 14:58:25.179503 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.output.dropout-dropout_233-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.output.dropout-dropout_233] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.output.dropout-dropout_233_grad] (stage_id:0) 
I1222 14:58:25.179577 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.intermediate.intermediate_act_fn-gelu_230-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.intermediate.intermediate_act_fn-gelu_230] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.output.dense-broadcast_matmul_231_b_grad] (stage_id:0) 
I1222 14:58:25.179632 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.intermediate.dense-broadcast_add_229-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.intermediate.dense-broadcast_add_229] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.intermediate.intermediate_act_fn-gelu_230_grad] (stage_id:0) 
I1222 14:58:25.179718 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.output.LayerNorm-layer_norm_227-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.output.LayerNorm-layer_norm_227] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.intermediate.dense-broadcast_matmul_228_b_grad] (stage_id:0) 
I1222 14:58:25.180393 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.output.LayerNorm-layer_norm_227-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.output.LayerNorm-layer_norm_227] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.output.LayerNorm-layer_norm_227_param_grad] (stage_id:0) 
I1222 14:58:25.180452 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.output-add_n_226-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.output-add_n_226] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.output.LayerNorm-layer_norm_227_grad] (stage_id:0) 
I1222 14:58:25.180512 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.output.LayerNorm-layer_norm_227-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.output.LayerNorm-layer_norm_227] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.output.LayerNorm-layer_norm_227_grad] (stage_id:0) 
I1222 14:58:25.180560 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.output.LayerNorm-layer_norm_227-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.output.LayerNorm-layer_norm_227] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.output.LayerNorm-layer_norm_227_grad] (stage_id:0) 
I1222 14:58:25.180615 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.output.dropout-dropout_225-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.output.dropout-dropout_225] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.output.dropout-dropout_225_grad] (stage_id:0) 
I1222 14:58:25.180672 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.self-reshape_222-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.self-reshape_222] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.output.dense-broadcast_matmul_223_b_grad] (stage_id:0) 
I1222 14:58:25.180727 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.self-transpose_213-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.self-transpose_213] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.self-batch_matmul_220_grad_a] (stage_id:0) 
I1222 14:58:25.180781 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.self.dropout-dropout_219-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.self.dropout-dropout_219] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.self-batch_matmul_220_grad_b] (stage_id:0) 
I1222 14:58:25.180835 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.self.dropout-dropout_219-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.self.dropout-dropout_219] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.self.dropout-dropout_219_grad] (stage_id:0) 
I1222 14:58:25.180915 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.self-softmax_218-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.self-softmax_218] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.self-softmax_218_grad] (stage_id:0) 
I1222 14:58:25.181514 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.output.LayerNorm-layer_norm_201-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.output.LayerNorm-layer_norm_201] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.self.value-broadcast_matmul_210_b_grad] (stage_id:0) 
I1222 14:58:25.181571 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.self-transpose_214-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.self-transpose_214] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.self-batch_matmul_215_grad_a] (stage_id:0) 
I1222 14:58:25.181624 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.5.attention.self-transpose_205-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.5.attention.self-transpose_205] (stage_id:0) -> [base_model.m_stage0.encoder.layer.5.attention.self-batch_matmul_215_grad_b] (stage_id:0) 
I1222 14:58:25.181718 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.output.LayerNorm-layer_norm_201-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.output.LayerNorm-layer_norm_201] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.output.LayerNorm-layer_norm_201_param_grad] (stage_id:0) 
I1222 14:58:25.181777 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.output-add_n_200-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.output-add_n_200] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.output.LayerNorm-layer_norm_201_grad] (stage_id:0) 
I1222 14:58:25.181828 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.output.LayerNorm-layer_norm_201-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.output.LayerNorm-layer_norm_201] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.output.LayerNorm-layer_norm_201_grad] (stage_id:0) 
I1222 14:58:25.181875 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.output.LayerNorm-layer_norm_201-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.output.LayerNorm-layer_norm_201] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.output.LayerNorm-layer_norm_201_grad] (stage_id:0) 
I1222 14:58:25.181928 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.output.dropout-dropout_199-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.output.dropout-dropout_199] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.output.dropout-dropout_199_grad] (stage_id:0) 
I1222 14:58:25.181985 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.intermediate.intermediate_act_fn-gelu_196-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.intermediate.intermediate_act_fn-gelu_196] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.output.dense-broadcast_matmul_197_b_grad] (stage_id:0) 
I1222 14:58:25.182070 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.intermediate.dense-broadcast_add_195-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.intermediate.dense-broadcast_add_195] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.intermediate.intermediate_act_fn-gelu_196_grad] (stage_id:0) 
I1222 14:58:25.182679 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.output.LayerNorm-layer_norm_193-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.output.LayerNorm-layer_norm_193] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.intermediate.dense-broadcast_matmul_194_b_grad] (stage_id:0) 
I1222 14:58:25.182739 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.output.LayerNorm-layer_norm_193-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.output.LayerNorm-layer_norm_193] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.output.LayerNorm-layer_norm_193_param_grad] (stage_id:0) 
I1222 14:58:25.182793 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.output-add_n_192-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.output-add_n_192] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.output.LayerNorm-layer_norm_193_grad] (stage_id:0) 
I1222 14:58:25.182845 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.output.LayerNorm-layer_norm_193-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.output.LayerNorm-layer_norm_193] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.output.LayerNorm-layer_norm_193_grad] (stage_id:0) 
I1222 14:58:25.182893 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.output.LayerNorm-layer_norm_193-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.output.LayerNorm-layer_norm_193] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.output.LayerNorm-layer_norm_193_grad] (stage_id:0) 
I1222 14:58:25.182945 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.output.dropout-dropout_191-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.output.dropout-dropout_191] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.output.dropout-dropout_191_grad] (stage_id:0) 
I1222 14:58:25.183002 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.self-reshape_188-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.self-reshape_188] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.output.dense-broadcast_matmul_189_b_grad] (stage_id:0) 
I1222 14:58:25.183059 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.self-transpose_179-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.self-transpose_179] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.self-batch_matmul_186_grad_a] (stage_id:0) 
I1222 14:58:25.183112 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.self.dropout-dropout_185-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.self.dropout-dropout_185] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.self-batch_matmul_186_grad_b] (stage_id:0) 
I1222 14:58:25.183167 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.self.dropout-dropout_185-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.self.dropout-dropout_185] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.self.dropout-dropout_185_grad] (stage_id:0) 
I1222 14:58:25.183248 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.self-softmax_184-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.self-softmax_184] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.self-softmax_184_grad] (stage_id:0) 
I1222 14:58:25.183838 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.output.LayerNorm-layer_norm_167-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.output.LayerNorm-layer_norm_167] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.self.value-broadcast_matmul_176_b_grad] (stage_id:0) 
I1222 14:58:25.183894 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.self-transpose_180-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.self-transpose_180] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.self-batch_matmul_181_grad_a] (stage_id:0) 
I1222 14:58:25.183948 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.4.attention.self-transpose_171-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.4.attention.self-transpose_171] (stage_id:0) -> [base_model.m_stage0.encoder.layer.4.attention.self-batch_matmul_181_grad_b] (stage_id:0) 
I1222 14:58:25.184041 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.output.LayerNorm-layer_norm_167-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.output.LayerNorm-layer_norm_167] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.output.LayerNorm-layer_norm_167_param_grad] (stage_id:0) 
I1222 14:58:25.184096 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.output-add_n_166-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.output-add_n_166] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.output.LayerNorm-layer_norm_167_grad] (stage_id:0) 
I1222 14:58:25.184149 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.output.LayerNorm-layer_norm_167-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.output.LayerNorm-layer_norm_167] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.output.LayerNorm-layer_norm_167_grad] (stage_id:0) 
I1222 14:58:25.184197 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.output.LayerNorm-layer_norm_167-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.output.LayerNorm-layer_norm_167] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.output.LayerNorm-layer_norm_167_grad] (stage_id:0) 
I1222 14:58:25.184250 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.output.dropout-dropout_165-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.output.dropout-dropout_165] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.output.dropout-dropout_165_grad] (stage_id:0) 
I1222 14:58:25.184310 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.intermediate.intermediate_act_fn-gelu_162-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.intermediate.intermediate_act_fn-gelu_162] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.output.dense-broadcast_matmul_163_b_grad] (stage_id:0) 
I1222 14:58:25.184389 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.intermediate.dense-broadcast_add_161-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.intermediate.dense-broadcast_add_161] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.intermediate.intermediate_act_fn-gelu_162_grad] (stage_id:0) 
I1222 14:58:25.185110 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.output.LayerNorm-layer_norm_159-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.output.LayerNorm-layer_norm_159] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.intermediate.dense-broadcast_matmul_160_b_grad] (stage_id:0) 
I1222 14:58:25.185169 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.output.LayerNorm-layer_norm_159-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.output.LayerNorm-layer_norm_159] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.output.LayerNorm-layer_norm_159_param_grad] (stage_id:0) 
I1222 14:58:25.185225 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.output-add_n_158-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.output-add_n_158] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.output.LayerNorm-layer_norm_159_grad] (stage_id:0) 
I1222 14:58:25.185278 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.output.LayerNorm-layer_norm_159-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.output.LayerNorm-layer_norm_159] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.output.LayerNorm-layer_norm_159_grad] (stage_id:0) 
I1222 14:58:25.185325 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.output.LayerNorm-layer_norm_159-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.output.LayerNorm-layer_norm_159] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.output.LayerNorm-layer_norm_159_grad] (stage_id:0) 
I1222 14:58:25.185379 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.output.dropout-dropout_157-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.output.dropout-dropout_157] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.output.dropout-dropout_157_grad] (stage_id:0) 
I1222 14:58:25.185436 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.self-reshape_154-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.self-reshape_154] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.output.dense-broadcast_matmul_155_b_grad] (stage_id:0) 
I1222 14:58:25.185492 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.self-transpose_145-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.self-transpose_145] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.self-batch_matmul_152_grad_a] (stage_id:0) 
I1222 14:58:25.185552 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.self.dropout-dropout_151-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.self.dropout-dropout_151] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.self-batch_matmul_152_grad_b] (stage_id:0) 
I1222 14:58:25.185634 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.self.dropout-dropout_151-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.self.dropout-dropout_151] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.self.dropout-dropout_151_grad] (stage_id:0) 
I1222 14:58:25.186255 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.self-softmax_150-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.self-softmax_150] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.self-softmax_150_grad] (stage_id:0) 
I1222 14:58:25.186316 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.output.LayerNorm-layer_norm_133-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.output.LayerNorm-layer_norm_133] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.self.value-broadcast_matmul_142_b_grad] (stage_id:0) 
I1222 14:58:25.186370 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.self-transpose_146-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.self-transpose_146] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.self-batch_matmul_147_grad_a] (stage_id:0) 
I1222 14:58:25.186424 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.3.attention.self-transpose_137-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.3.attention.self-transpose_137] (stage_id:0) -> [base_model.m_stage0.encoder.layer.3.attention.self-batch_matmul_147_grad_b] (stage_id:0) 
I1222 14:58:25.186520 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.output.LayerNorm-layer_norm_133-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.output.LayerNorm-layer_norm_133] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.output.LayerNorm-layer_norm_133_param_grad] (stage_id:0) 
I1222 14:58:25.186578 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.output-add_n_132-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.output-add_n_132] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.output.LayerNorm-layer_norm_133_grad] (stage_id:0) 
I1222 14:58:25.186631 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.output.LayerNorm-layer_norm_133-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.output.LayerNorm-layer_norm_133] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.output.LayerNorm-layer_norm_133_grad] (stage_id:0) 
I1222 14:58:25.186677 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.output.LayerNorm-layer_norm_133-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.output.LayerNorm-layer_norm_133] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.output.LayerNorm-layer_norm_133_grad] (stage_id:0) 
I1222 14:58:25.186731 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.output.dropout-dropout_131-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.output.dropout-dropout_131] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.output.dropout-dropout_131_grad] (stage_id:0) 
I1222 14:58:25.186789 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.intermediate.intermediate_act_fn-gelu_128-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.intermediate.intermediate_act_fn-gelu_128] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.output.dense-broadcast_matmul_129_b_grad] (stage_id:0) 
I1222 14:58:25.186870 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.intermediate.dense-broadcast_add_127-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.intermediate.dense-broadcast_add_127] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.intermediate.intermediate_act_fn-gelu_128_grad] (stage_id:0) 
I1222 14:58:25.187454 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.output.LayerNorm-layer_norm_125-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.output.LayerNorm-layer_norm_125] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.intermediate.dense-broadcast_matmul_126_b_grad] (stage_id:0) 
I1222 14:58:25.187520 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.output.LayerNorm-layer_norm_125-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.output.LayerNorm-layer_norm_125] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.output.LayerNorm-layer_norm_125_param_grad] (stage_id:0) 
I1222 14:58:25.187575 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.output-add_n_124-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.output-add_n_124] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.output.LayerNorm-layer_norm_125_grad] (stage_id:0) 
I1222 14:58:25.187628 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.output.LayerNorm-layer_norm_125-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.output.LayerNorm-layer_norm_125] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.output.LayerNorm-layer_norm_125_grad] (stage_id:0) 
I1222 14:58:25.187676 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.output.LayerNorm-layer_norm_125-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.output.LayerNorm-layer_norm_125] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.output.LayerNorm-layer_norm_125_grad] (stage_id:0) 
I1222 14:58:25.187728 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.output.dropout-dropout_123-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.output.dropout-dropout_123] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.output.dropout-dropout_123_grad] (stage_id:0) 
I1222 14:58:25.187786 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.self-reshape_120-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.self-reshape_120] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.output.dense-broadcast_matmul_121_b_grad] (stage_id:0) 
I1222 14:58:25.187844 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.self-transpose_111-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.self-transpose_111] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.self-batch_matmul_118_grad_a] (stage_id:0) 
I1222 14:58:25.187897 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.self.dropout-dropout_117-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.self.dropout-dropout_117] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.self-batch_matmul_118_grad_b] (stage_id:0) 
I1222 14:58:25.187979 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.self.dropout-dropout_117-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.self.dropout-dropout_117] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.self.dropout-dropout_117_grad] (stage_id:0) 
I1222 14:58:25.188553 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.self-softmax_116-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.self-softmax_116] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.self-softmax_116_grad] (stage_id:0) 
I1222 14:58:25.188614 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.output.LayerNorm-layer_norm_99-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.output.LayerNorm-layer_norm_99] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.self.value-broadcast_matmul_108_b_grad] (stage_id:0) 
I1222 14:58:25.188669 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.self-transpose_112-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.self-transpose_112] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.self-batch_matmul_113_grad_a] (stage_id:0) 
I1222 14:58:25.188722 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.2.attention.self-transpose_103-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.2.attention.self-transpose_103] (stage_id:0) -> [base_model.m_stage0.encoder.layer.2.attention.self-batch_matmul_113_grad_b] (stage_id:0) 
I1222 14:58:25.188817 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.output.LayerNorm-layer_norm_99-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.output.LayerNorm-layer_norm_99] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.output.LayerNorm-layer_norm_99_param_grad] (stage_id:0) 
I1222 14:58:25.188874 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.output-add_n_98-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.output-add_n_98] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.output.LayerNorm-layer_norm_99_grad] (stage_id:0) 
I1222 14:58:25.188926 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.output.LayerNorm-layer_norm_99-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.output.LayerNorm-layer_norm_99] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.output.LayerNorm-layer_norm_99_grad] (stage_id:0) 
I1222 14:58:25.188974 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.output.LayerNorm-layer_norm_99-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.output.LayerNorm-layer_norm_99] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.output.LayerNorm-layer_norm_99_grad] (stage_id:0) 
I1222 14:58:25.189028 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.output.dropout-dropout_97-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.output.dropout-dropout_97] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.output.dropout-dropout_97_grad] (stage_id:0) 
I1222 14:58:25.189113 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.intermediate.intermediate_act_fn-gelu_94-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.intermediate.intermediate_act_fn-gelu_94] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.output.dense-broadcast_matmul_95_b_grad] (stage_id:0) 
I1222 14:58:25.189695 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.intermediate.dense-broadcast_add_93-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.intermediate.dense-broadcast_add_93] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.intermediate.intermediate_act_fn-gelu_94_grad] (stage_id:0) 
I1222 14:58:25.189756 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.output.LayerNorm-layer_norm_91-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.output.LayerNorm-layer_norm_91] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.intermediate.dense-broadcast_matmul_92_b_grad] (stage_id:0) 
I1222 14:58:25.189811 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.output.LayerNorm-layer_norm_91-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.output.LayerNorm-layer_norm_91] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.output.LayerNorm-layer_norm_91_param_grad] (stage_id:0) 
I1222 14:58:25.189867 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.output-add_n_90-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.output-add_n_90] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.output.LayerNorm-layer_norm_91_grad] (stage_id:0) 
I1222 14:58:25.189921 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.output.LayerNorm-layer_norm_91-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.output.LayerNorm-layer_norm_91] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.output.LayerNorm-layer_norm_91_grad] (stage_id:0) 
I1222 14:58:25.189968 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.output.LayerNorm-layer_norm_91-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.output.LayerNorm-layer_norm_91] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.output.LayerNorm-layer_norm_91_grad] (stage_id:0) 
I1222 14:58:25.190021 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.output.dropout-dropout_89-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.output.dropout-dropout_89] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.output.dropout-dropout_89_grad] (stage_id:0) 
I1222 14:58:25.190079 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.self-reshape_86-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.self-reshape_86] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.output.dense-broadcast_matmul_87_b_grad] (stage_id:0) 
I1222 14:58:25.190135 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.self-transpose_77-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.self-transpose_77] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.self-batch_matmul_84_grad_a] (stage_id:0) 
I1222 14:58:25.190217 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.self.dropout-dropout_83-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.self.dropout-dropout_83] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.self-batch_matmul_84_grad_b] (stage_id:0) 
I1222 14:58:25.190796 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.self.dropout-dropout_83-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.self.dropout-dropout_83] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.self.dropout-dropout_83_grad] (stage_id:0) 
I1222 14:58:25.190853 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.self-softmax_82-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.self-softmax_82] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.self-softmax_82_grad] (stage_id:0) 
I1222 14:58:25.190912 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.output.LayerNorm-layer_norm_65-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.output.LayerNorm-layer_norm_65] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.self.value-broadcast_matmul_74_b_grad] (stage_id:0) 
I1222 14:58:25.190964 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.self-transpose_78-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.self-transpose_78] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.self-batch_matmul_79_grad_a] (stage_id:0) 
I1222 14:58:25.191018 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.1.attention.self-transpose_69-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.1.attention.self-transpose_69] (stage_id:0) -> [base_model.m_stage0.encoder.layer.1.attention.self-batch_matmul_79_grad_b] (stage_id:0) 
I1222 14:58:25.191110 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.output.LayerNorm-layer_norm_65-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.output.LayerNorm-layer_norm_65] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.output.LayerNorm-layer_norm_65_param_grad] (stage_id:0) 
I1222 14:58:25.191166 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.output-add_n_64-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.output-add_n_64] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.output.LayerNorm-layer_norm_65_grad] (stage_id:0) 
I1222 14:58:25.191219 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.output.LayerNorm-layer_norm_65-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.output.LayerNorm-layer_norm_65] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.output.LayerNorm-layer_norm_65_grad] (stage_id:0) 
I1222 14:58:25.191267 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.output.LayerNorm-layer_norm_65-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.output.LayerNorm-layer_norm_65] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.output.LayerNorm-layer_norm_65_grad] (stage_id:0) 
I1222 14:58:25.191320 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.output.dropout-dropout_63-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.output.dropout-dropout_63] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.output.dropout-dropout_63_grad] (stage_id:0) 
I1222 14:58:25.191408 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.intermediate.intermediate_act_fn-gelu_60-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.intermediate.intermediate_act_fn-gelu_60] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.output.dense-broadcast_matmul_61_b_grad] (stage_id:0) 
I1222 14:58:25.191987 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.intermediate.dense-broadcast_add_59-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.intermediate.dense-broadcast_add_59] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.intermediate.intermediate_act_fn-gelu_60_grad] (stage_id:0) 
I1222 14:58:25.192047 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.output.LayerNorm-layer_norm_57-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.output.LayerNorm-layer_norm_57] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.intermediate.dense-broadcast_matmul_58_b_grad] (stage_id:0) 
I1222 14:58:25.192103 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.output.LayerNorm-layer_norm_57-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.output.LayerNorm-layer_norm_57] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.output.LayerNorm-layer_norm_57_param_grad] (stage_id:0) 
I1222 14:58:25.192160 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.output-add_n_56-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.output-add_n_56] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.output.LayerNorm-layer_norm_57_grad] (stage_id:0) 
I1222 14:58:25.192212 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.output.LayerNorm-layer_norm_57-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.output.LayerNorm-layer_norm_57] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.output.LayerNorm-layer_norm_57_grad] (stage_id:0) 
I1222 14:58:25.192260 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.output.LayerNorm-layer_norm_57-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.output.LayerNorm-layer_norm_57] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.output.LayerNorm-layer_norm_57_grad] (stage_id:0) 
I1222 14:58:25.192313 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.output.dropout-dropout_55-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.output.dropout-dropout_55] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.output.dropout-dropout_55_grad] (stage_id:0) 
I1222 14:58:25.192371 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.self-reshape_52-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.self-reshape_52] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.output.dense-broadcast_matmul_53_b_grad] (stage_id:0) 
I1222 14:58:25.192427 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.self-transpose_43-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.self-transpose_43] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.self-batch_matmul_50_grad_a] (stage_id:0) 
I1222 14:58:25.192517 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.self.dropout-dropout_49-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.self.dropout-dropout_49] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.self-batch_matmul_50_grad_b] (stage_id:0) 
I1222 14:58:25.193109 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.self.dropout-dropout_49-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.self.dropout-dropout_49] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.self.dropout-dropout_49_grad] (stage_id:0) 
I1222 14:58:25.193164 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.self-softmax_48-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.self-softmax_48] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.self-softmax_48_grad] (stage_id:0) 
I1222 14:58:25.193224 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.embeddings.dropout-dropout_25-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.embeddings.dropout-dropout_25] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.self.value-broadcast_matmul_40_b_grad] (stage_id:0) 
I1222 14:58:25.193277 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.self-transpose_44-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.self-transpose_44] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.self-batch_matmul_45_grad_a] (stage_id:0) 
I1222 14:58:25.193331 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.encoder.layer.0.attention.self-transpose_35-output_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.encoder.layer.0.attention.self-transpose_35] (stage_id:0) -> [base_model.m_stage0.encoder.layer.0.attention.self-batch_matmul_45_grad_b] (stage_id:0) 
I1222 14:58:25.193424 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.embeddings.dropout-dropout_25-mask_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.embeddings.dropout-dropout_25] (stage_id:0) -> [base_model.m_stage0.embeddings.dropout-dropout_25_grad] (stage_id:0) 
I1222 14:58:25.193481 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.embeddings.LayerNorm-layer_norm_24-normalized_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.embeddings.LayerNorm-layer_norm_24] (stage_id:0) -> [base_model.m_stage0.embeddings.LayerNorm-layer_norm_24_param_grad] (stage_id:0) 
I1222 14:58:25.193548 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.embeddings-broadcast_add_23-z_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.embeddings-broadcast_add_23] (stage_id:0) -> [base_model.m_stage0.embeddings.LayerNorm-layer_norm_24_grad] (stage_id:0) 
I1222 14:58:25.193603 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.embeddings.LayerNorm-layer_norm_24-mean_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.embeddings.LayerNorm-layer_norm_24] (stage_id:0) -> [base_model.m_stage0.embeddings.LayerNorm-layer_norm_24_grad] (stage_id:0) 
I1222 14:58:25.193651 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.embeddings.LayerNorm-layer_norm_24-inv_variance_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.embeddings.LayerNorm-layer_norm_24] (stage_id:0) -> [base_model.m_stage0.embeddings.LayerNorm-layer_norm_24_grad] (stage_id:0) 
I1222 14:58:25.193754 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.embeddings.position_embeddings-gather_20-out_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.embeddings.position_embeddings-gather_20] (stage_id:0) -> [base_model.m_stage0.embeddings-broadcast_add_23_y_grad_reduce_sum_like] (stage_id:0) 
I1222 14:58:25.194327 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model.m_stage0.embeddings-slice_19-y_0-stage_id_0](buffer_size:4) 
 from [base_model.m_stage0.embeddings-slice_19] (stage_id:0) -> [base_model.m_stage0.embeddings.position_embeddings-gather_20_grad] (stage_id:0) 
I1222 14:58:25.194391 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model-identity_15-out_0-stage_id_0](buffer_size:4) 
 from [base_model-identity_15] (stage_id:0) -> [base_model.m_stage0.embeddings.word_embeddings-gather_18_grad] (stage_id:0) 
I1222 14:58:25.194445 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-base_model-identity_16-out_0-stage_id_0](buffer_size:4) 
 from [base_model-identity_16] (stage_id:0) -> [base_model.m_stage0.embeddings.token_type_embeddings-gather_21_grad] (stage_id:0) 
I1222 14:58:25.195029 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-_train_data_loader-hierarchical_parallel_cast_8-out_0-stage_id_0](buffer_size:4) 
 from [_train_data_loader-hierarchical_parallel_cast_8] (stage_id:0) -> [base_model-identity_15] (stage_id:0) 
I1222 14:58:25.195098 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-_train_data_loader-hierarchical_parallel_cast_11-out_0-stage_id_0](buffer_size:4) 
 from [_train_data_loader-hierarchical_parallel_cast_11] (stage_id:0) -> [base_model-identity_16] (stage_id:0) 
I1222 14:58:25.195152 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-_train_data_loader-hierarchical_parallel_cast_10-out_0-stage_id_0](buffer_size:4) 
 from [_train_data_loader-hierarchical_parallel_cast_10] (stage_id:0) -> [base_model-identity_17] (stage_id:0) 
I1222 14:58:25.195749 85103 pipeline_buffer_pass.cpp:212] 
 Insert buffer op pair : src_buffer = <System-Pipeline-Buffer-Op_-base_model-identity_440-out_0>(buffer_size:1) , dst_buffer = <System-Pipeline-Buffer-Op_-base_model-identity_440-out_0-stage_id_1>(buffer_size:1) 
 from [base_model-identity_440] (stage_id:0) -> [base_model-identity_441] (stage_id:1) 
I1222 14:58:25.195811 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-_train_data_loader-hierarchical_parallel_cast_10-out_0-stage_id_1](buffer_size:4) 
 from [_train_data_loader-hierarchical_parallel_cast_10] (stage_id:0) -> [base_model-identity_442] (stage_id:1) 
I1222 14:58:25.196355 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-_train_data_loader-hierarchical_parallel_cast_9-out_0-stage_id_1](buffer_size:4) 
 from [_train_data_loader-hierarchical_parallel_cast_9] (stage_id:0) -> [reshape_872] (stage_id:1) 
I1222 14:58:25.196420 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-_train_data_loader-hierarchical_parallel_cast_13-out_0-stage_id_1](buffer_size:4) 
 from [_train_data_loader-hierarchical_parallel_cast_13] (stage_id:0) -> [expand_dims_880] (stage_id:1) 
I1222 14:58:25.196475 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-_train_data_loader-hierarchical_parallel_cast_12-out_0-stage_id_1](buffer_size:4) 
 from [_train_data_loader-hierarchical_parallel_cast_12] (stage_id:0) -> [reshape_884] (stage_id:1) 
I1222 14:58:25.196537 85103 pipeline_buffer_pass.cpp:117] 
 Insert buffer op : [System-Pipeline-Buffer-Op_-_train_data_loader-hierarchical_parallel_cast_14-out_0-stage_id_1](buffer_size:4) 
 from [_train_data_loader-hierarchical_parallel_cast_14] (stage_id:0) -> [multiply_891] (stage_id:1) 
I1222 14:58:25.197829 85103 pipeline_buffer_pass.cpp:212] 
 Insert buffer op pair : src_buffer = <System-Pipeline-Buffer-Op_-base_model-identity_441_grad-out_0>(buffer_size:1) , dst_buffer = <System-Pipeline-Buffer-Op_-base_model-identity_441_grad-out_0-stage_id_0>(buffer_size:1) 
 from [base_model-identity_441_grad] (stage_id:1) -> [base_model-identity_440_grad] (stage_id:0) 
I1222 14:58:26.192438 85103 global.h:43] DeleteGlobal N7oneflow7JobDescE
I1222 14:58:27.388588 85103 global.h:36] NewGlobal N7oneflow7JobDescE
F1222 14:58:46.099306 85103 memory_allocator.cpp:58] 
  File "/root/muzhailong/oneflow/oneflow/core/memory/memory_allocator.cpp", line 58, in Allocate
    device->Alloc(options, &ptr, size)
out of memory
